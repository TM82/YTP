{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任意のクエリでTF-IDF求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import functools as ft\n",
    "import json\n",
    "import os\n",
    "import random as rd\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from operator import itemgetter\n",
    "from operator import itemgetter\n",
    "\n",
    "import controll_text as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('mayfes/json_data/2ndLayer/')\n",
    "querys = []\n",
    "for file in files:\n",
    "    query,_ = os.path.splitext(file)\n",
    "    if query.startswith('.'):\n",
    "        pass\n",
    "    else:\n",
    "        querys.append(query)\n",
    "print(len(querys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今回のクエリ: ['プログラミング', '映画', '予算', '地震', '募集', '中国', 'ID', '本願寺', 'ローン', '一戸建て']\n",
      "残りクエリ数: 498\n",
      "今回のクエリ: ['番組', '満載', '透析', '千葉', 'デザイン', '分譲', '履修', '連合', 'http', '画像']\n",
      "残りクエリ数: 488\n",
      "今回のクエリ: ['カリキュラム', '夢', 'インターネット', '専門', 'カタログ', '休', '福祉', '受験', '全国', '気象']\n",
      "残りクエリ数: 478\n",
      "今回のクエリ: ['性', '公立', '掲載', '理解', '各種', '幕張', 'テーマ', '配送', '目黒', '月行事']\n",
      "残りクエリ数: 468\n",
      "今回のクエリ: ['日吉', '〜', '居酒屋', 'バー', '一覧', '駅', 'センター', '急性', '推薦', 'アマゾン']\n",
      "残りクエリ数: 458\n",
      "今回のクエリ: ['ゲーム', '個人', '医学', '年間', 'アットホーム', '免許', '方法', '病気', '委員', '本文']\n",
      "残りクエリ数: 448\n",
      "今回のクエリ: ['申込', '新橋', '宿泊', '人間', '国会図書館', '附属', 'アリーナ', 'ニュース', '駐車', 'PS']\n",
      "残りクエリ数: 438\n",
      "今回のクエリ: ['高知', '期間', '支払い', 'AO', 'ターミナル', '挨拶', '製品', '出演', '治療', '計画']\n",
      "残りクエリ数: 428\n",
      "今回のクエリ: ['体験', 'PlayStation', 'フライト', '位置', '観光', 'ぞう', 'セガ', '神奈川', '単位', '分野']\n",
      "残りクエリ数: 418\n",
      "今回のクエリ: ['工業', '庁舎', '教室', 'ビジョン', 'ご覧', '特集', 'ページ', '木', '証明', 'アリ']\n",
      "残りクエリ数: 408\n",
      "今回のクエリ: ['出願', 'システム', '会議', 'ビジネス', '邑楽', '表情', '質問', '帝京大学', '専攻', '提供']\n",
      "残りクエリ数: 398\n",
      "今回のクエリ: ['ボランティア', '郁', '商品', 'プロジェクト', '水', '胃', '就職', '試験', 'Web', '相談']\n",
      "残りクエリ数: 388\n",
      "今回のクエリ: ['水面', '卒業生', 'パソコン', '住吉', '独り言', '用語', '消化', '攻略', 'ロジスティクス', 'スクール']\n",
      "残りクエリ数: 378\n",
      "今回のクエリ: ['CHINTAI', '入場', '者', '所蔵', '検索', '会員', '資料', '主義', '当せん', '間取り']\n",
      "残りクエリ数: 368\n",
      "今回のクエリ: ['コース', '操作', 'PDF', 'インテリア', 'ユニセフ', '糖尿', '開通', 'オープン', '終電', '指定']\n",
      "残りクエリ数: 358\n",
      "今回のクエリ: ['定員', '定期', 'センサ', '気温', 'ミュージックビデオ', '在', '印刷', '地層', '予約', '希望']\n",
      "残りクエリ数: 348\n",
      "今回のクエリ: ['文京', 'シネマズ', '支部', '総会', '府', 'アーティスト', '曜日', '入力', '実証', '自宅']\n",
      "残りクエリ数: 338\n",
      "今回のクエリ: ['所在地', '調査', '郵便', '協会', '仙台', '国民', '修士', '住宅', '神経', 'フェリー']\n",
      "残りクエリ数: 328\n",
      "今回のクエリ: ['日本', 'クリニック', '党', '団体', '品川', 'KB', '課程', '一般', '授与', '同窓会']\n",
      "残りクエリ数: 318\n",
      "今回のクエリ: ['読み取り', '役割', '土地', '－', '展示', '校舎', '基本', '政治', '医院', '都市']\n",
      "残りクエリ数: 308\n",
      "今回のクエリ: ['カウントダウン', 'R', 'オンライン', '瀬戸大橋', '改革', 'カード', '東京', 'お知らせ', '経済', '奨学']\n",
      "残りクエリ数: 298\n",
      "今回のクエリ: ['就学', '人員', '塾', '解決', '生徒', '新築', '電話', '問い合わせ', '日程', 'マップ']\n",
      "残りクエリ数: 288\n",
      "今回のクエリ: ['学費', '廃棄', 'ダウンロード', '購入', '予報', '科学', '学会', '受付', '周辺', 'おすすめ']\n",
      "残りクエリ数: 278\n",
      "今回のクエリ: ['修理', '皆様', '確認', '現職', '女性', 'ON', '働', '設置', '介護', '組織']\n",
      "残りクエリ数: 268\n",
      "今回のクエリ: ['番号', '処分', '政党', '収容', '北口', '中古', '学科', '小児科', '避難', 'エムオン']\n",
      "残りクエリ数: 258\n",
      "今回のクエリ: ['イオン', '葬儀', 'RPG', '方針', '熊本大学', 'デジタル', 'MUSIC', '検討', '市', '評価']\n",
      "残りクエリ数: 248\n",
      "今回のクエリ: ['高齢', '保険', 'お客様', 'ログイン', '活用', '下小鳥', '障害', '予備校', '窓口', 'カメラ']\n",
      "残りクエリ数: 238\n",
      "今回のクエリ: ['策定', '文化', '魅力', 'アンパン', '助成', '管理', '林間', 'スーモ', '要項', 'ホテル']\n",
      "残りクエリ数: 228\n",
      "今回のクエリ: ['マンガ', '協議', 'TODO:検索したい単語を記入', '卒業', '注意', 'コンテンツ', '紛争', '外国', '式典', '渋谷']\n",
      "残りクエリ数: 218\n",
      "今回のクエリ: ['須崎', '公共', '始発', '温度', '電車', '画面', '授業', '天気', '国立', '島忠']\n",
      "残りクエリ数: 208\n",
      "今回のクエリ: ['機関', '行政', '準備', '会費', '予測', '人工', '徒歩', '説明', 'パナソニック', '同志社']\n",
      "残りクエリ数: 198\n",
      "今回のクエリ: ['ネット', '合格', '人気', 'シネマ', 'チーム', '花粉', '建築', 'スポット', '東急', '編集']\n",
      "残りクエリ数: 188\n",
      "今回のクエリ: ['空港', 'ベルサール', '手続き', '使用', '科', '科目', '住所', 'アクセス', '慶應義塾', 'ダン']\n",
      "残りクエリ数: 178\n",
      "今回のクエリ: ['猪名川', '中学校', 'プレゼント', '公開', '法要', '相手', '疾患', '税込', '招待', '先進']\n",
      "残りクエリ数: 168\n",
      "今回のクエリ: ['会', '明細', '保育', 'アパート', '業務', '保護', '設備', 'ホームページ', '成田空港', 'アカデミー']\n",
      "残りクエリ数: 158\n",
      "今回のクエリ: ['学習', 'ポイント', '入院', '人材', '模試', '通報', 'フューチャースクール', '日', 'ソフトウェア', 'トップページ']\n",
      "残りクエリ数: 148\n",
      "今回のクエリ: ['人', 'Amazon', '母校', 'チケット', '政', '選手', '博士', '選手権', 'スケジュール', '外来']\n",
      "残りクエリ数: 138\n",
      "今回のクエリ: ['鳥', '皮膚', 'ウェブ', '宝くじ', '大東建託', 'マーガレット', '市立', '受診', '賃貸', '金額']\n",
      "残りクエリ数: 128\n",
      "今回のクエリ: ['キャンペーン', '支援', '交流', '環境', '放射', '対策', '不動産', '医師', '患者', 'エリー']\n",
      "残りクエリ数: 118\n",
      "今回のクエリ: ['ライブ', '設定', '条件', '地域', '求人', '創業', '学都', 'TV', '選挙', '受験生']\n",
      "残りクエリ数: 108\n",
      "今回のクエリ: ['QR', '登録', '書類', '看護', '早稲田大学', '最新', 'サンプラザ', 'ポータルサイト', '数字', '世界']\n",
      "残りクエリ数: 98\n",
      "今回のクエリ: ['歌詞', '留学', 'グローバル', 'みなとみらい', '予定', '行', '試合', '人々', '担当', '会場']\n",
      "残りクエリ数: 88\n",
      "今回のクエリ: ['セキュリティ', '休診', '保健', '臨床', '中小', '法人', '土', 'ファンクラブ', '航空', '店']\n",
      "残りクエリ数: 78\n",
      "今回のクエリ: ['運動', '通知', '腎臓', '東大', '花水木', '公益', 'ヴィジョン', '習慣', '蔵書', '映像']\n",
      "残りクエリ数: 68\n",
      "今回のクエリ: ['書', '改定', 'リーグ', 'ウォーカープラス', '推進', 'コープ', '部屋', '連携', '指導', '育成']\n",
      "残りクエリ数: 58\n",
      "今回のクエリ: ['物流', 'ミオホール', '都区', '学', '地図', '降水', '脱出', 'パスワード', '市民', '国会']\n",
      "残りクエリ数: 48\n",
      "今回のクエリ: ['診療', 'プロフィール', '報酬', '昭和', '共和', '機器', '住友不動産', '循環', 'グッズ', '大曲']\n",
      "残りクエリ数: 38\n",
      "今回のクエリ: ['教諭', 'セガフェス', 'ウィル・パートナーズ', 'SUUMO', '貢献', '大阪大学', '応援', '工学部', '材料', 'サービス']\n",
      "残りクエリ数: 28\n",
      "今回のクエリ: ['方', 'プリンセス', '定款', 'エリア', '表示', '飛行機', 'NPO', '舞台', '外科', '理念']\n",
      "残りクエリ数: 18\n",
      "今回のクエリ: ['圧力', 'スペース', '料金', '県政', '政府', '救急', '施設', 'コンサート', '略称', 'ディスコグラフィー']\n",
      "残りクエリ数: 8\n",
      "今回のクエリ: ['関西', '提示', '参加', 'ファイル', '申', 'au', '小学生', '利用']\n",
      "残りクエリ数: 0\n"
     ]
    }
   ],
   "source": [
    "picked_number = 10\n",
    "while len(querys) > 0:\n",
    "    picked_number = min(picked_number,len(querys))\n",
    "    random_querys = rd.sample(querys,picked_number)\n",
    "    for query in random_querys:\n",
    "        querys.remove(query)\n",
    "    print('今回のクエリ: ' + str(random_querys))\n",
    "    print('残りクエリ数: ' + str(len(querys)))\n",
    "\n",
    "\n",
    "    query_texts = dict()\n",
    "    for query in random_querys:\n",
    "        row_data = open('mayfes/json_data/2ndLayer/{0}.json'.format(query), 'r')\n",
    "        data = json.load(row_data)\n",
    "        text_list = list(map(lambda d: ft.reduce(lambda l1, l2: l1+l2, d[\"texts\"]), filter(lambda d: d[\"texts\"] !=[], data)))\n",
    "        query_texts[query] = text_list\n",
    "\n",
    "\n",
    "    noun_conditions = ct.make_noun_conditions(except_nouns=['/', '(', ')', '>', '<', '-', '.','\"','_', 'ー','＿','ー',';',':','·','...'])\n",
    "    verb_conditions = ct.make_verb_conditions(except_verbs=[], verb_types = [])\n",
    "    query_words = {}\n",
    "    for k, v in query_texts.items():\n",
    "        query_words[k] = list(map(ft.partial(ct.extract_words, noun_conditions,verb_conditions), v))\n",
    "    # query_words[\"サイト\"][0:1]\n",
    "\n",
    "\n",
    "\n",
    "    def tfidf(full_texts, target_words_list):\n",
    "        dictionary = corpora.Dictionary(full_texts)\n",
    "        n_words = len(dictionary.token2id)\n",
    "        id2token = {v: k for k, v in dictionary.token2id.items()}\n",
    "        full_corpus = map(dictionary.doc2bow, full_texts)\n",
    "        target_corpus = map(dictionary.doc2bow, target_words_list)\n",
    "        tfidf_model = models.TfidfModel(copy.deepcopy(full_corpus))\n",
    "        tfidf_vectors_by_tuple = list(tfidf_model[copy.deepcopy(target_corpus)])\n",
    "\n",
    "        # TF-IDF行列を算出\n",
    "        vectors = []\n",
    "        for v_by_tuple in tfidf_vectors_by_tuple:\n",
    "            vector = [0]*n_words \n",
    "            for t in v_by_tuple:\n",
    "                vector[t[0]] = t[1]\n",
    "            vectors.append(vector)\n",
    "        # 行列を転置\n",
    "        vectors_t = list(zip(*vectors))\n",
    "\n",
    "        #単語ごとにTF-IDFベクトルの平均値を求める\n",
    "        vectors_t2 = [list(it) for it in list(zip(*vectors))]\n",
    "        ave_vec = list(map(lambda l: sum(l)/len(l), vectors_t2))\n",
    "        tfidf_ave_dict = {i:v for i, v in enumerate(ave_vec)}\n",
    "\n",
    "        word_dict = dict()\n",
    "        for k,v in tfidf_ave_dict.items():\n",
    "            word_dict[id2token[k]] = v\n",
    "\n",
    "        return sorted(word_dict.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # 全文\n",
    "    full_texts = ft.reduce(lambda l1, l2:l1+l2, query_words.values())\n",
    "\n",
    "\n",
    "    # 出力\n",
    "    for query in random_querys:\n",
    "        target_words_list = query_words[query]\n",
    "        ranking = tfidf(full_texts, target_words_list)\n",
    "        f = open('./tfidf_text/2ndLayer/{0}.txt'.format(query), 'w')\n",
    "        for x in ranking:\n",
    "            f.write(str(x) + \"\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
