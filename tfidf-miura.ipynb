{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任意のクエリでTF-IDF求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import functools as ft\n",
    "import json\n",
    "import os\n",
    "import random as rd\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from operator import itemgetter\n",
    "from operator import itemgetter\n",
    "\n",
    "import controll_text as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('mayfes/json_data/1stLayer/')\n",
    "querys = []\n",
    "for file in files:\n",
    "    query,_ = os.path.splitext(file)\n",
    "    if query.startswith('.'):\n",
    "        pass\n",
    "    else:\n",
    "        querys.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今回のクエリ: ['駒場', '入学', '特性', '稲', '病院', '主体', '協同', '医療', '消費', '入試']\n",
      "残りクエリ数: 41\n",
      "YEYE\n"
     ]
    }
   ],
   "source": [
    "picked_number = 10\n",
    "random_querys = rd.sample(querys,picked_number)\n",
    "for query in random_querys:\n",
    "    querys.remove(query)\n",
    "print('今回のクエリ: ' + str(random_querys))\n",
    "print('残りクエリ数: ' + str(len(querys)))\n",
    "\n",
    "\n",
    "query_texts = dict()\n",
    "for query in random_querys:\n",
    "    row_data = open('mayfes/json_data/1stLayer/{0}.json'.format(query), 'r')\n",
    "    data = json.load(row_data)\n",
    "    text_list = list(map(lambda d: ft.reduce(lambda l1, l2: l1+l2, d[\"texts\"]), filter(lambda d: d[\"texts\"] !=[], data)))\n",
    "    query_texts[query] = text_list\n",
    "    \n",
    "\n",
    "noun_conditions = ct.make_noun_conditions(except_nouns=['/', '(', ')', '>', '<', '-', '.','\"','_', 'ー','＿','ー',';',':','·','...'])\n",
    "verb_conditions = ct.make_verb_conditions(except_verbs=[], verb_types = [])\n",
    "query_words = {}\n",
    "for k, v in query_texts.items():\n",
    "    query_words[k] = list(map(ft.partial(ct.extract_words, noun_conditions,verb_conditions), v))\n",
    "# query_words[\"サイト\"][0:1]\n",
    "\n",
    "\n",
    "\n",
    "def tfidf(full_texts, target_words_list):\n",
    "    dictionary = corpora.Dictionary(full_texts)\n",
    "    n_words = len(dictionary.token2id)\n",
    "    id2token = {v: k for k, v in dictionary.token2id.items()}\n",
    "    full_corpus = map(dictionary.doc2bow, full_texts)\n",
    "    target_corpus = map(dictionary.doc2bow, target_words_list)\n",
    "    tfidf_model = models.TfidfModel(copy.deepcopy(full_corpus))\n",
    "    tfidf_vectors_by_tuple = list(tfidf_model[copy.deepcopy(target_corpus)])\n",
    "\n",
    "    # TF-IDF行列を算出\n",
    "    vectors = []\n",
    "    for v_by_tuple in tfidf_vectors_by_tuple:\n",
    "        vector = [0]*n_words \n",
    "        for t in v_by_tuple:\n",
    "            vector[t[0]] = t[1]\n",
    "        vectors.append(vector)\n",
    "    # 行列を転置\n",
    "    vectors_t = list(zip(*vectors))\n",
    "\n",
    "    #単語ごとにTF-IDFベクトルの平均値を求める\n",
    "    vectors_t2 = [list(it) for it in list(zip(*vectors))]\n",
    "    ave_vec = list(map(lambda l: sum(l)/len(l), vectors_t2))\n",
    "    tfidf_ave_dict = {i:v for i, v in enumerate(ave_vec)}\n",
    "\n",
    "    word_dict = dict()\n",
    "    for k,v in tfidf_ave_dict.items():\n",
    "        word_dict[id2token[k]] = v\n",
    "\n",
    "    return sorted(word_dict.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "# 全文\n",
    "full_texts = ft.reduce(lambda l1, l2:l1+l2, query_words.values())\n",
    "\n",
    "\n",
    "# 出力\n",
    "for query in random_querys:\n",
    "    target_words_list = query_words[query]\n",
    "    ranking = tfidf(full_texts, target_words_list)\n",
    "    f = open('./tfidf_text/1stLayer/{0}.txt'.format(query), 'w')\n",
    "    for x in ranking:\n",
    "        f.write(str(x) + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
