{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任意のクエリでTF-IDF求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import functools as ft\n",
    "import json\n",
    "import os\n",
    "import random as rd\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from operator import itemgetter\n",
    "from operator import itemgetter\n",
    "\n",
    "import controll_text as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('mayfes/json_data/2ndLayer/')\n",
    "querys = []\n",
    "for file in files:\n",
    "    query,_ = os.path.splitext(file)\n",
    "    if query.startswith('.'):\n",
    "        pass\n",
    "    else:\n",
    "        querys.append(query)\n",
    "print(len(querys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今回のクエリ: ['ターミナル', 'パナソニック', '申込', '都市', 'コンサート', '本文', '定員', '方法', 'Amazon', '北口']\n",
      "残りクエリ数: 490\n",
      "今回のクエリ: ['最新', '臨床', '皮膚', '会費', '参加', '推薦', '条件', '修士', 'ソフトウェア', '日程']\n",
      "残りクエリ数: 480\n",
      "今回のクエリ: ['博士', '環境', 'アンパン', '治療', '政治', '位置', '学都', '学習', '邑楽', 'カウントダウン']\n",
      "残りクエリ数: 470\n",
      "今回のクエリ: ['習慣', 'エムオン', '相手', '府', '資料', '患者', 'ディスコグラフィー', '気象', '住友不動産', '葬儀']\n",
      "残りクエリ数: 460\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2c70e7cc8dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_querys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mtarget_words_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mranking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_words_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tfidf_text/2ndLayer/{0}.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mranking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2c70e7cc8dc2>\u001b[0m in \u001b[0;36mtfidf\u001b[0;34m(full_texts, target_words_list)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtarget_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_words_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtfidf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTfidfModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtfidf_vectors_by_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# TF-IDF行列を算出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/miuratakahiro/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/miuratakahiro/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/gensim/models/tfidfmodel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, eps)\u001b[0m\n\u001b[1;32m    378\u001b[0m         vector = [\n\u001b[1;32m    379\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermid_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_array\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         ]\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/miuratakahiro/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/gensim/models/tfidfmodel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    378\u001b[0m         vector = [\n\u001b[1;32m    379\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermid_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_array\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         ]\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "picked_number = 10\n",
    "while len(querys) > 0:\n",
    "    picked_number = min(picked_number,len(querys))\n",
    "    random_querys = rd.sample(querys,picked_number)\n",
    "    for query in random_querys:\n",
    "        querys.remove(query)\n",
    "    print('今回のクエリ: ' + str(random_querys))\n",
    "    print('残りクエリ数: ' + str(len(querys)))\n",
    "\n",
    "\n",
    "    query_texts = dict()\n",
    "    for query in random_querys:\n",
    "        row_data = open('mayfes/json_data/2ndLayer/{0}.json'.format(query), 'r')\n",
    "        data = json.load(row_data)\n",
    "        text_list = list(map(lambda d: ft.reduce(lambda l1, l2: l1+l2, d[\"texts\"]), filter(lambda d: d[\"texts\"] !=[], data)))\n",
    "        query_texts[query] = text_list\n",
    "\n",
    "\n",
    "    noun_conditions = ct.make_noun_conditions(except_nouns=['/', '(', ')', '>', '<', '-', '.','\"','_', 'ー','＿','ー',';',':','·','...'])\n",
    "    verb_conditions = ct.make_verb_conditions(except_verbs=[], verb_types = [])\n",
    "    query_words = {}\n",
    "    for k, v in query_texts.items():\n",
    "        query_words[k] = list(map(ft.partial(ct.extract_words, noun_conditions,verb_conditions), v))\n",
    "    # query_words[\"サイト\"][0:1]\n",
    "\n",
    "\n",
    "\n",
    "    def tfidf(full_texts, target_words_list):\n",
    "        dictionary = corpora.Dictionary(full_texts)\n",
    "        n_words = len(dictionary.token2id)\n",
    "        id2token = {v: k for k, v in dictionary.token2id.items()}\n",
    "        full_corpus = map(dictionary.doc2bow, full_texts)\n",
    "        target_corpus = map(dictionary.doc2bow, target_words_list)\n",
    "        tfidf_model = models.TfidfModel(copy.deepcopy(full_corpus))\n",
    "        tfidf_vectors_by_tuple = list(tfidf_model[copy.deepcopy(target_corpus)])\n",
    "\n",
    "        # TF-IDF行列を算出\n",
    "        vectors = []\n",
    "        for v_by_tuple in tfidf_vectors_by_tuple:\n",
    "            vector = [0]*n_words \n",
    "            for t in v_by_tuple:\n",
    "                vector[t[0]] = t[1]\n",
    "            vectors.append(vector)\n",
    "        # 行列を転置\n",
    "        vectors_t = list(zip(*vectors))\n",
    "\n",
    "        #単語ごとにTF-IDFベクトルの平均値を求める\n",
    "        vectors_t2 = [list(it) for it in list(zip(*vectors))]\n",
    "        ave_vec = list(map(lambda l: sum(l)/len(l), vectors_t2))\n",
    "        tfidf_ave_dict = {i:v for i, v in enumerate(ave_vec)}\n",
    "\n",
    "        word_dict = dict()\n",
    "        for k,v in tfidf_ave_dict.items():\n",
    "            word_dict[id2token[k]] = v\n",
    "\n",
    "        return sorted(word_dict.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # 全文\n",
    "    full_texts = ft.reduce(lambda l1, l2:l1+l2, query_words.values())\n",
    "\n",
    "\n",
    "    # 出力\n",
    "    for query in random_querys:\n",
    "        target_words_list = query_words[query]\n",
    "        ranking = tfidf(full_texts, target_words_list)\n",
    "        f = open('./tfidf_text/2ndLayer/{0}.txt'.format(query), 'w')\n",
    "        for x in ranking:\n",
    "            f.write(str(x) + \"\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
